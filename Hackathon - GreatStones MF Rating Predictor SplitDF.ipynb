{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data frams from csv file\n",
    "df_other_specs = pd.read_csv(\"other_specs.csv\")\n",
    "df_fund_specs = pd.read_csv(\"fund_specs.csv\")\n",
    "df_fund_ratios = pd.read_csv(\"fund_ratios.csv\")\n",
    "df_submission_file = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "df_return_3Y = pd.read_csv(\"return_3year.csv\")\n",
    "#df_return_5Y = pd.read_csv(\"return_5year.csv\")\n",
    "#df_return_10Y = pd.read_csv(\"return_10year.csv\")\n",
    "\n",
    "## Others to be considered later are bond allocations for blend & value funds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linkage = df_fund_ratios.filter(['fund_id', 'tag'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create features that may be useful in each df\n",
    "#1. Fund_Specs: None to be created\n",
    "df_fund_specs.drop(columns=['currency','total_assets', 'inception_date'], inplace=True)\n",
    "\n",
    "#2. Other_Specs : Create one feature for each (fund value / category value)\n",
    "df_other_specs['2018_return_ratio'] = df_other_specs['2018_return_fund']/df_other_specs['2018_return_category']\n",
    "df_other_specs['2017_return_ratio'] = df_other_specs['2017_return_fund']/df_other_specs['2017_category_return']\n",
    "df_other_specs['2016_return_ratio'] = df_other_specs['2016_return_fund']/df_other_specs['2016_return_category']\n",
    "df_other_specs['2016_return_ratio'] = df_other_specs['2016_return_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "df_other_specs['2015_return_ratio'] = df_other_specs['2015_return_fund']/df_other_specs['category_return_2015']\n",
    "df_other_specs['2014_return_ratio'] = df_other_specs['2014_return_fund']/df_other_specs['2014_category_return']\n",
    "df_other_specs['2013_return_ratio'] = df_other_specs['2013_return_fund']/df_other_specs['2013_category_return']\n",
    "df_other_specs['2012_return_ratio'] = df_other_specs['2012_fund_return']/df_other_specs['2012_return_category']\n",
    "df_other_specs['2011_return_ratio'] = df_other_specs['2011_return_fund']/df_other_specs['2011_return_category']\n",
    "df_other_specs['2010_return_ratio'] = df_other_specs['2010_return_fund']/df_other_specs['2010_return_category']\n",
    "\n",
    "df_other_specs['1Y_return_ratio'] = df_other_specs['1_year_return_fund']/df_other_specs['category_return_1year']\n",
    "df_other_specs['1Y_return_ratio']=  df_other_specs['1Y_return_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "\n",
    "#df_other_specs['category_return_1year']\n",
    "#df_other_specs['category_return_1year'] =df_other_specs['category_return_1year'].where((df_other_specs['category_return_1year']==0)|(df_other_specs['category_return_1year'].isnull()),0.00001)\n",
    "#df_other_specs['1Y_return_ratio'] = df_other_specs['1_year_return_fund']/df_other_specs['category_return_1year']\n",
    "#df_other_specs['1Y_return_ratio'] = (df_other_specs['1_year_return_fund']/df_other_specs['category_return_1year']).where((df_other_specs['category_return_1year'].notnull()) | (df_other_specs['category_return_1year']==0) ,0)\n",
    "\n",
    "df_other_specs['3M_return_ratio'] = df_other_specs['fund_return_3months']/df_other_specs['3_months_return_category']\n",
    "df_other_specs['3M_return_ratio'] = df_other_specs['3M_return_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "df_other_specs['1M_return_ratio'] = df_other_specs['1_month_fund_return']/df_other_specs['category_return_1month']\n",
    "df_other_specs['1M_return_ratio'] = df_other_specs['1M_return_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "df_other_specs['ytd_return_ratio'] = df_other_specs['ytd_return_fund']/df_other_specs['ytd_return_category']\n",
    "df_other_specs['ytd_return_ratio'] = df_other_specs['ytd_return_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "\n",
    "df_other_specs['years_up_down'] = df_other_specs['years_up']-df_other_specs['years_down']\n",
    "df_other_specs['cash_to_stock_ratio'] = (df_other_specs['cash_percent_of_portfolio']+df_other_specs['bond_percentage_of_porfolio'])/df_other_specs['stock_percent_of_portfolio']\n",
    "df_other_specs['cash_to_stock_ratio']=  df_other_specs['cash_to_stock_ratio'].replace((np.inf, -np.inf), (0, 0))\n",
    "df_other_specs.drop(columns=[\n",
    "    '2018_return_fund','2018_return_category',\n",
    "    '2017_return_fund','2017_category_return',\n",
    "    '2016_return_fund','2016_return_category',\n",
    "    '2015_return_fund','category_return_2015',\n",
    "    '2014_return_fund','2014_category_return',\n",
    "    '2013_return_fund','2013_category_return',\n",
    "    '2012_fund_return','2012_return_category',\n",
    "    '2011_return_fund','2011_return_category',\n",
    "    '2010_return_fund','2010_return_category',\n",
    "    '1_year_return_fund','category_return_1year',\n",
    "    'fund_return_3months','3_months_return_category',\n",
    "    '1_month_fund_return','category_return_1month',\n",
    "    'ytd_return_fund','ytd_return_category',\n",
    "    'cash_percent_of_portfolio', 'stock_percent_of_portfolio','bond_percentage_of_porfolio',\n",
    "    'years_up','years_down','greatstone_rating'], inplace=True)\n",
    "\n",
    "## DF3 : Fund Ratios : \n",
    "df_fund_ratios.drop(columns=['mmc','fund_id','pb_ratio','ps_ratio','pc_ratio','pe_ratio'],inplace=True)\n",
    "\n",
    "\n",
    "#DF4 : 3 year return : Retain = fund_return_3years, 3_years_return_category\n",
    "\n",
    "df_return_3Y['3yrs_treynor_ratio_fund'] = pd.to_numeric(df_return_3Y['3yrs_treynor_ratio_fund'], downcast=\"float\",errors='coerce')\n",
    "\n",
    "df_return_3Y['3y_treynor_ratio'] = df_return_3Y['3yrs_treynor_ratio_fund']/df_return_3Y['3yrs_treynor_ratio_category']\n",
    "df_return_3Y['3y_alpha_ratio'] = df_return_3Y['3_years_alpha_fund']/df_return_3Y['3_years_alpha_category']\n",
    "df_return_3Y['3y_sharpe_ratio'] = df_return_3Y['3yrs_sharpe_ratio_fund']/df_return_3Y['3yrs_sharpe_ratio_category']\n",
    "df_return_3Y['3y_rma_ratio'] = df_return_3Y['3_years_return_mean_annual_fund']/df_return_3Y['3_years_return_mean_annual_category']\n",
    "df_return_3Y['3y_beta_ratio'] = df_return_3Y['fund_beta_3years']/df_return_3Y['category_beta_3years']\n",
    "df_return_3Y['3y_r2_ratio'] = df_return_3Y['3years_fund_r_squared']/df_return_3Y['3years_category_r_squared']\n",
    "df_return_3Y['3y_std_ratio'] = df_return_3Y['3years_fund_std']/df_return_3Y['3years_category_std']\n",
    "df_return_3Y['3y_return_ratio'] = df_return_3Y['fund_return_3years']/df_return_3Y['3_years_return_category']\n",
    "\n",
    "df_return_3Y.drop(columns=[\n",
    "    '3yrs_treynor_ratio_fund','3yrs_treynor_ratio_category',\n",
    "    '3_years_alpha_fund','3_years_alpha_category',\n",
    "    '3yrs_sharpe_ratio_fund','3yrs_sharpe_ratio_category',\n",
    "    '3_years_return_mean_annual_fund','3_years_return_mean_annual_category',\n",
    "    'fund_beta_3years','category_beta_3years',\n",
    "    '3years_fund_r_squared','3years_category_r_squared',\n",
    "    '3years_fund_std','3years_category_std',\n",
    "    'fund_return_3years','3_years_return_category'],inplace=True)\n",
    "\n",
    "#### DF 5Y & 10 year can be added later\n",
    "#DF5 : 5 year return : Retain = 5_years_return_fund, 5_years_return_category\n",
    "#df_return_5Y = df_return_5Y.filter(['tag','5_years_return_fund', '5_years_return_category'],axis=1)\n",
    "\n",
    "\n",
    "#DF6 : 10 year return : Retain = 10_years_return_fund, 10_years_return_category\n",
    "#df_return_10Y = df_return_10Y.filter(['fund_id','10_years_return_fund', '10_years_return_category'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create master data\n",
    "# DF1 : Linkage. Drop no columns\n",
    "# DF2 : Fund_Specs \n",
    "df_dataset = pd.merge(df_linkage,df_fund_specs,on='tag')\n",
    "\n",
    "#DF3 : other_specs \n",
    "df_dataset = pd.merge(df_dataset,df_other_specs,on='tag')\n",
    "\n",
    "# DF4 : Fund ratios : \n",
    "df_dataset = pd.merge(df_dataset,df_fund_ratios,on='tag')\n",
    "\n",
    "#DF5 : 3 year return :\n",
    "df_return_3Y = df_return_3Y.filter(['tag','fund_return_3years', '3_years_return_category'],axis=1)\n",
    "df_dataset = pd.merge(df_dataset,df_return_3Y,on='tag')\n",
    "\n",
    "#print(df_dataset.columns)\n",
    "#print(df_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columsn as object are converted to float\n",
    "df_dataset['pc_ratio'] = pd.to_numeric(df_dataset['pc_ratio'], downcast=\"float\",errors='coerce')\n",
    "df_dataset['pb_ratio'] = pd.to_numeric(df_dataset['pb_ratio'], downcast=\"float\",errors='coerce')\n",
    "df_dataset['ps_ratio'] = pd.to_numeric(df_dataset['ps_ratio'], downcast=\"float\",errors='coerce')\n",
    "df_dataset['pe_ratio'] = pd.to_numeric(df_dataset['pe_ratio'], downcast=\"float\",errors='coerce')\n",
    "df_dataset['mmc'] = pd.to_numeric(df_dataset['mmc'], downcast=\"float\",errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute blanks in investment_class with 'Unkowwn'\n",
    "df_dataset['investment_class'] = df_dataset['investment_class'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute blanks in fund_size with 'Unkowwn'\n",
    "#print(df_dataset['fund_size'].isna().sum())\n",
    "df_dataset['fund_size'] = df_dataset['fund_size'].fillna('Unknown')\n",
    "#print(df_dataset['fund_size'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_dataset['yield'].isna().sum())\n",
    "# Impute missing yield with zero [may need to change later]\n",
    "df_dataset['yield'] = df_dataset['yield'].fillna(0)\n",
    "#print(df_dataset['yield'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['fund_id','tag','investment_class','greatstone_rating','fund_size']\n",
    "for i in df_dataset.columns:\n",
    "    if i not in exclude :\n",
    "        df_dataset[i] = round(pd.to_numeric(df_dataset[i]),3)\n",
    "        df_dataset[i] = df_dataset[i].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.to_csv(\"dataset_full21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Value = df_dataset[df_dataset['investment_class']=='Value']\n",
    "df_Blend = df_dataset[df_dataset['investment_class']=='Blend']\n",
    "df_Growth = df_dataset[df_dataset['investment_class']=='Growth']\n",
    "df_Unknown = df_dataset[df_dataset['investment_class']=='Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "\n",
    "data_subsets = [df_Value,df_Blend,df_Growth,df_Unknown]\n",
    "for df in data_subsets:\n",
    "    exclude = ['fund_id','tag','investment_class','yield','greatstone_rating','fund_size']\n",
    "    for i in df.columns:\n",
    "        if i not in exclude :            \n",
    "            df[i] = pd.to_numeric(df[i])\n",
    "            df[i] = df[i].fillna(df[i].mean())\n",
    "    \n",
    "    # Following code could be on the full dataset, however doiing it here as this code is for encoding. \n",
    "    df.fund_size[df.fund_size == 'Unknown']=0\n",
    "    df.fund_size[df.fund_size == 'Small']=1\n",
    "    df.fund_size[df.fund_size == 'Medium']=2\n",
    "    df.fund_size[df.fund_size == 'Large']=3\n",
    "    \n",
    "    #Min-max scale all data columns\n",
    "\n",
    "    df[['yield', \n",
    "           'fund_size', 'return_ytd', 'pc_ratio', 'pb_ratio', 'pe_ratio',\n",
    "           'portfolio_convertable', 'portfolio_others', 'mmc', 'ps_ratio',\n",
    "           'fund_return_3years', 'category_ratio_net_annual_expense',\n",
    "           'portfolio_preferred', '2018_return_ratio', '2017_return_ratio',\n",
    "           '2016_return_ratio', '2015_return_ratio', '2014_return_ratio',\n",
    "           '2013_return_ratio', '2012_return_ratio', '2011_return_ratio',\n",
    "           '2010_return_ratio', '1Y_return_ratio', '3M_return_ratio',\n",
    "           '1M_return_ratio', 'ytd_return_ratio', 'years_up_down',\n",
    "           'cash_to_stock_ratio', 'fund_ratio_net_annual_expense']] = mms.fit_transform(df[['yield', \n",
    "           'fund_size', 'return_ytd', 'pc_ratio', 'pb_ratio', 'pe_ratio',\n",
    "           'portfolio_convertable', 'portfolio_others', 'mmc', 'ps_ratio',\n",
    "           'fund_return_3years', 'category_ratio_net_annual_expense',\n",
    "           'portfolio_preferred', '2018_return_ratio', '2017_return_ratio',\n",
    "           '2016_return_ratio', '2015_return_ratio', '2014_return_ratio',\n",
    "           '2013_return_ratio', '2012_return_ratio', '2011_return_ratio',\n",
    "           '2010_return_ratio', '1Y_return_ratio', '3M_return_ratio',\n",
    "           '1M_return_ratio', 'ytd_return_ratio', 'years_up_down',\n",
    "           'cash_to_stock_ratio', 'fund_ratio_net_annual_expense']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_dataset.corr()\n",
    "df_corr.to_csv(\"correlation1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 33)\n",
      "(1301, 33)\n",
      "(25000, 2)\n",
      "(6551, 2)\n",
      "(5250, 1)\n",
      "(1301, 1)\n",
      "['tag']\n",
      "(5250, 2)\n",
      "(1301, 2)\n",
      "(5250, 30)\n",
      "(1301, 30)\n",
      "(5250, 29)\n",
      "(1301, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\narayanan.p\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "## Fulll set of code for VALUE\n",
    "df_Value_train = df_Value[df_Value.greatstone_rating.notnull()]\n",
    "df_Value_test = df_Value[df_Value.greatstone_rating.isnull()]\n",
    "\n",
    "\n",
    "## 'New Code'\n",
    "df_linkage = df_dataset.filter(['fund_id', 'tag'],axis=1)\n",
    "df_linkage_Value = df_Value.filter(['fund_id', 'tag'],axis=1)\n",
    "df_Value_train_keys = df_Value_train.filter(['tag'],axis=1)\n",
    "df_Value_test_keys = df_Value_test.filter(['tag'],axis=1)\n",
    "\n",
    "keys_train = list(df_Value_train_keys.columns.values)\n",
    "i1 = df_linkage_Value.set_index(keys_train).index\n",
    "i2 = df_Value_train_keys.set_index(keys_train).index\n",
    "df_Value_linkage_train = df_linkage_Value[i1.isin(i2)]\n",
    "df_Value_linkage_test = df_linkage_Value[~i1.isin(i2)]\n",
    "df_Value_train_X = df_Value_train.drop(labels='greatstone_rating',axis=1)\n",
    "df_Value_train_y = df_Value_train['greatstone_rating']\n",
    "\n",
    "# Drop funid & tag columns in both test & train \n",
    "df_Value_train_X.drop(columns=['fund_id','tag'],inplace=True)\n",
    "df_Value_test.drop(columns=['fund_id','tag','greatstone_rating'],inplace=True)\n",
    "\n",
    "# OneHot encode investment class in both train_X & test\n",
    "inv_class = pd.get_dummies(df_Value_train_X['investment_class'],drop_first=True)\n",
    "df_Value_train_X.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Value_train_X = pd.concat([df_Value_train_X,inv_class],axis=1)\n",
    "\n",
    "inv_class = pd.get_dummies(df_Value_test['investment_class'],drop_first=True)\n",
    "df_Value_test.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Value_test = pd.concat([df_Value_test,inv_class],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8217, 33)\n",
      "(2081, 33)\n"
     ]
    }
   ],
   "source": [
    "## Fulll set of code for Blend\n",
    "df_Blend_train = df_Blend[df_Blend.greatstone_rating.notnull()]\n",
    "df_Blend_test = df_Blend[df_Blend.greatstone_rating.isnull()]\n",
    "print(df_Blend_train.shape)\n",
    "print(df_Blend_test.shape)\n",
    "\n",
    "## 'New Code'\n",
    "df_linkage = df_dataset.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_linkage_Blend = df_Blend.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_Blend_train_keys = df_Blend_train.filter(['tag'],axis=1)\n",
    "df_Blend_test_keys = df_Blend_test.filter(['tag'],axis=1)\n",
    "\n",
    "keys_train = list(df_Blend_train_keys.columns.values)\n",
    "i1 = df_linkage_Blend.set_index(keys_train).index\n",
    "i2 = df_Blend_train_keys.set_index(keys_train).index\n",
    "df_Blend_linkage_train = df_linkage_Blend[i1.isin(i2)]\n",
    "df_Blend_linkage_test = df_linkage_Blend[~i1.isin(i2)]\n",
    "\n",
    "df_Blend_train_X = df_Blend_train.drop(labels='greatstone_rating',axis=1)\n",
    "df_Blend_train_y = df_Blend_train['greatstone_rating']\n",
    "\n",
    "# Drop funid & tag columns in both test & train \n",
    "df_Blend_train_X.drop(columns=['fund_id','tag'],inplace=True)\n",
    "df_Blend_test.drop(columns=['fund_id','tag','greatstone_rating'],inplace=True)\n",
    "\n",
    "# OneHot encode investment class in both train_X & test\n",
    "inv_class = pd.get_dummies(df_Blend_train_X['investment_class'],drop_first=True)\n",
    "df_Blend_train_X.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Blend_train_X = pd.concat([df_Blend_train_X,inv_class],axis=1)\n",
    "\n",
    "inv_class = pd.get_dummies(df_Blend_test['investment_class'],drop_first=True)\n",
    "df_Blend_test.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Blend_test = pd.concat([df_Blend_test,inv_class],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5328, 33)\n",
      "(1343, 33)\n"
     ]
    }
   ],
   "source": [
    "## Fulll set of code for Growth\n",
    "df_Growth_train = df_Growth[df_Growth.greatstone_rating.notnull()]\n",
    "df_Growth_test = df_Growth[df_Growth.greatstone_rating.isnull()]\n",
    "print(df_Growth_train.shape)\n",
    "print(df_Growth_test.shape)\n",
    "\n",
    "## 'New Code'\n",
    "df_linkage = df_dataset.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_linkage_Growth = df_Growth.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_Growth_train_keys = df_Growth_train.filter(['tag'],axis=1)\n",
    "df_Growth_test_keys = df_Growth_test.filter(['tag'],axis=1)\n",
    "\n",
    "keys_train = list(df_Growth_train_keys.columns.values)\n",
    "i1 = df_linkage_Growth.set_index(keys_train).index\n",
    "i2 = df_Growth_train_keys.set_index(keys_train).index\n",
    "df_Growth_linkage_train = df_linkage_Growth[i1.isin(i2)]\n",
    "df_Growth_linkage_test = df_linkage_Growth[~i1.isin(i2)]\n",
    "\n",
    "df_Growth_train_X = df_Growth_train.drop(labels='greatstone_rating',axis=1)\n",
    "df_Growth_train_y = df_Growth_train['greatstone_rating']\n",
    "\n",
    "# Drop funid & tag columns in both test & train \n",
    "df_Growth_train_X.drop(columns=['fund_id','tag'],inplace=True)\n",
    "df_Growth_test.drop(columns=['fund_id','tag','greatstone_rating'],inplace=True)\n",
    "\n",
    "# OneHot encode investment class in both train_X & test\n",
    "inv_class = pd.get_dummies(df_Growth_train_X['investment_class'],drop_first=True)\n",
    "df_Growth_train_X.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Growth_train_X = pd.concat([df_Growth_train_X,inv_class],axis=1)\n",
    "\n",
    "inv_class = pd.get_dummies(df_Growth_test['investment_class'],drop_first=True)\n",
    "df_Growth_test.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Growth_test = pd.concat([df_Growth_test,inv_class],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 33)\n",
      "(275, 33)\n"
     ]
    }
   ],
   "source": [
    "## Fulll set of code for Unknown\n",
    "df_Unknown_train = df_Unknown[df_Unknown.greatstone_rating.notnull()]\n",
    "df_Unknown_test = df_Unknown[df_Unknown.greatstone_rating.isnull()]\n",
    "print(df_Unknown_train.shape)\n",
    "print(df_Unknown_test.shape)\n",
    "\n",
    "## 'New Code'\n",
    "df_linkage = df_dataset.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_linkage_Unknown = df_Unknown.filter(['fund_id', 'tag'],axis=1)\n",
    "\n",
    "df_Unknown_train_keys = df_Unknown_train.filter(['tag'],axis=1)\n",
    "df_Unknown_test_keys = df_Unknown_test.filter(['tag'],axis=1)\n",
    "\n",
    "keys_train = list(df_Unknown_train_keys.columns.values)\n",
    "i1 = df_linkage_Unknown.set_index(keys_train).index\n",
    "i2 = df_Unknown_train_keys.set_index(keys_train).index\n",
    "df_Unknown_linkage_train = df_linkage_Unknown[i1.isin(i2)]\n",
    "df_Unknown_linkage_test = df_linkage_Unknown[~i1.isin(i2)]\n",
    "\n",
    "df_Unknown_train_X = df_Unknown_train.drop(labels='greatstone_rating',axis=1)\n",
    "df_Unknown_train_y = df_Unknown_train['greatstone_rating']\n",
    "\n",
    "# Drop funid & tag columns in both test & train \n",
    "df_Unknown_train_X.drop(columns=['fund_id','tag'],inplace=True)\n",
    "df_Unknown_test.drop(columns=['fund_id','tag','greatstone_rating'],inplace=True)\n",
    "\n",
    "# OneHot encode investment class in both train_X & test\n",
    "inv_class = pd.get_dummies(df_Unknown_train_X['investment_class'],drop_first=True)\n",
    "df_Unknown_train_X.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Unknown_train_X = pd.concat([df_Unknown_train_X,inv_class],axis=1)\n",
    "\n",
    "inv_class = pd.get_dummies(df_Unknown_test['investment_class'],drop_first=True)\n",
    "df_Unknown_test.drop(['investment_class'],axis=1,inplace=True)\n",
    "df_Unknown_test = pd.concat([df_Unknown_test,inv_class],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1301, 2)\n"
     ]
    }
   ],
   "source": [
    "## MODEL 3 : RAMDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=25, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model.fit(df_Value_train_X,df_Value_train_y)\n",
    "predictions = rf_model.predict(df_Value_test)\n",
    "\n",
    "Value_predicted_ratings = pd.DataFrame(predictions)\n",
    "\n",
    "df_Value_linkage_test.reset_index(drop=True, inplace=True)\n",
    "Value_predicted_ratings.reset_index(drop=True, inplace=True)\n",
    "df_Value_final_ratings = pd.concat([df_Value_linkage_test,Value_predicted_ratings],axis=1)\n",
    "df_Value_final_ratings.drop(columns=['tag'],inplace=True)\n",
    "print(df_Value_final_ratings.shape)\n",
    "df_Value_final_ratings.to_csv(\"df_Value_final_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2081, 2)\n"
     ]
    }
   ],
   "source": [
    "rf_model1 = RandomForestClassifier(n_estimators=25, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model1.fit(df_Blend_train_X,df_Blend_train_y)\n",
    "predictions1 = rf_model1.predict(df_Blend_test)\n",
    "\n",
    "Blend_predicted_ratings = pd.DataFrame(predictions1)\n",
    "\n",
    "df_Blend_linkage_test.reset_index(drop=True, inplace=True)\n",
    "Blend_predicted_ratings.reset_index(drop=True, inplace=True)\n",
    "df_Blend_final_ratings = pd.concat([df_Blend_linkage_test,Blend_predicted_ratings],axis=1)\n",
    "df_Blend_final_ratings.drop(columns=['tag'],inplace=True)\n",
    "print(df_Blend_final_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1343, 2)\n"
     ]
    }
   ],
   "source": [
    "rf_model2 = RandomForestClassifier(n_estimators=25, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model2.fit(df_Growth_train_X,df_Growth_train_y)\n",
    "predictions2 = rf_model2.predict(df_Growth_test)\n",
    "\n",
    "Growth_predicted_ratings = pd.DataFrame(predictions2)\n",
    "\n",
    "df_Growth_linkage_test.reset_index(drop=True, inplace=True)\n",
    "Growth_predicted_ratings.reset_index(drop=True, inplace=True)\n",
    "df_Growth_final_ratings = pd.concat([df_Growth_linkage_test,Growth_predicted_ratings],axis=1)\n",
    "df_Growth_final_ratings.drop(columns=['tag'],inplace=True)\n",
    "print(df_Growth_final_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 2)\n"
     ]
    }
   ],
   "source": [
    "rf_model3 = RandomForestClassifier(n_estimators=25, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model3.fit(df_Unknown_train_X,df_Unknown_train_y)\n",
    "predictions3 = rf_model3.predict(df_Unknown_test)\n",
    "\n",
    "Unknown_predicted_ratings = pd.DataFrame(predictions3)\n",
    "\n",
    "df_Unknown_linkage_test.reset_index(drop=True, inplace=True)\n",
    "Unknown_predicted_ratings.reset_index(drop=True, inplace=True)\n",
    "df_Unknown_final_ratings = pd.concat([df_Unknown_linkage_test,Unknown_predicted_ratings],axis=1)\n",
    "df_Unknown_final_ratings.drop(columns=['tag'],inplace=True)\n",
    "print(df_Unknown_final_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fund_id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>468b76c0-a276-45b9-ad76-1a9d6c336ed6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cd9b1f78-e450-489f-b6e5-ece691d5c021</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7723006e-720e-4c97-825f-1752cd112736</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37c33326-b1fb-4208-a7df-08f7ead749da</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1052147-38d7-4981-8b8c-b3a0dcda8aed</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>668a58e7-5bee-41fd-9e23-963aa2f08f01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>96c3122c-eea0-4d39-b4ed-c1647b03f834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>80001be5-fde4-4f20-a8c3-ec295aed5960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>4d555bb4-ada5-4a1c-8a01-0827477dd7e5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>6b5b4d1a-f208-4a6b-88ce-1b42ed63ef2e</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fund_id    0\n",
       "0    468b76c0-a276-45b9-ad76-1a9d6c336ed6  2.0\n",
       "1    cd9b1f78-e450-489f-b6e5-ece691d5c021  1.0\n",
       "2    7723006e-720e-4c97-825f-1752cd112736  0.0\n",
       "3    37c33326-b1fb-4208-a7df-08f7ead749da  3.0\n",
       "4    d1052147-38d7-4981-8b8c-b3a0dcda8aed  2.0\n",
       "..                                    ...  ...\n",
       "270  668a58e7-5bee-41fd-9e23-963aa2f08f01  3.0\n",
       "271  96c3122c-eea0-4d39-b4ed-c1647b03f834  0.0\n",
       "272  80001be5-fde4-4f20-a8c3-ec295aed5960  0.0\n",
       "273  4d555bb4-ada5-4a1c-8a01-0827477dd7e5  0.0\n",
       "274  6b5b4d1a-f208-4a6b-88ce-1b42ed63ef2e  2.0\n",
       "\n",
       "[275 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Value_final_ratings.rename(columns={\"0\": \"greatstone_rating\"})\n",
    "df_Growth_final_ratings.rename(columns={\"0\": \"greatstone_rating\"})\n",
    "df_Blend_final_ratings.rename(columns={\"0\": \"greatstone_rating\"})\n",
    "df_Unknown_final_ratings.rename(columns={\"0\": \"greatstone_rating\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_Value_final_ratings,df_Blend_final_ratings,df_Growth_final_ratings,df_Unknown_final_ratings]\n",
    "final_result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fund_id</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>f0e1829f-0bcc-43e7-9759-c66efdca37d4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1e3ebfe5-644b-4a3b-92df-a94bdf8b22e0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1ec88986-c424-4d42-b3d1-f0a50d25e1b7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>02ece6b9-00e2-4698-bbd5-a51793e3653e</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>e1c1618c-4e4b-4c22-b9ae-468a9abdf7a8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>37392a99-d692-49bd-aece-b957cc6d16b3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>9ecf9c73-fb54-4abf-b6c3-d10f8787ff4d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>d2b9cae9-1e3e-4ce3-b614-eb37bde0d971</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>600d3d36-425c-47b2-803a-7fb2f3c100c6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1aa22f3d-1861-42a0-a850-e92f0f780f1e</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0bbecd0e-5b50-434e-a30f-f53b4d968137</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3f19c8e6-38f9-437e-b588-51124d7e37d1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>fa2e64ce-b440-44c6-bc28-e060de5248d0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>a3b472c5-c360-4ae0-8b87-910895c2741b</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>5b43840a-c410-4c05-94ae-0a6ab17a99d6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>668a58e7-5bee-41fd-9e23-963aa2f08f01</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>96c3122c-eea0-4d39-b4ed-c1647b03f834</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>80001be5-fde4-4f20-a8c3-ec295aed5960</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>4d555bb4-ada5-4a1c-8a01-0827477dd7e5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>6b5b4d1a-f208-4a6b-88ce-1b42ed63ef2e</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fund_id    0\n",
       "255  f0e1829f-0bcc-43e7-9759-c66efdca37d4  4.0\n",
       "256  1e3ebfe5-644b-4a3b-92df-a94bdf8b22e0  3.0\n",
       "257  1ec88986-c424-4d42-b3d1-f0a50d25e1b7  0.0\n",
       "258  02ece6b9-00e2-4698-bbd5-a51793e3653e  4.0\n",
       "259  e1c1618c-4e4b-4c22-b9ae-468a9abdf7a8  3.0\n",
       "260  37392a99-d692-49bd-aece-b957cc6d16b3  2.0\n",
       "261  9ecf9c73-fb54-4abf-b6c3-d10f8787ff4d  1.0\n",
       "262  d2b9cae9-1e3e-4ce3-b614-eb37bde0d971  3.0\n",
       "263  600d3d36-425c-47b2-803a-7fb2f3c100c6  2.0\n",
       "264  1aa22f3d-1861-42a0-a850-e92f0f780f1e  4.0\n",
       "265  0bbecd0e-5b50-434e-a30f-f53b4d968137  2.0\n",
       "266  3f19c8e6-38f9-437e-b588-51124d7e37d1  0.0\n",
       "267  fa2e64ce-b440-44c6-bc28-e060de5248d0  2.0\n",
       "268  a3b472c5-c360-4ae0-8b87-910895c2741b  3.0\n",
       "269  5b43840a-c410-4c05-94ae-0a6ab17a99d6  3.0\n",
       "270  668a58e7-5bee-41fd-9e23-963aa2f08f01  3.0\n",
       "271  96c3122c-eea0-4d39-b4ed-c1647b03f834  0.0\n",
       "272  80001be5-fde4-4f20-a8c3-ec295aed5960  0.0\n",
       "273  4d555bb4-ada5-4a1c-8a01-0827477dd7e5  0.0\n",
       "274  6b5b4d1a-f208-4a6b-88ce-1b42ed63ef2e  2.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder linkage_test to match the submission file\n",
    "final_result = final_result.set_index('fund_id')\n",
    "final_result = final_result.reindex(index=df_submission_file['fund_id'])\n",
    "final_result = final_result.reset_index()\n",
    "final_result.to_csv(\"Subission_Narayanan_SplitDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 1 : Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "model = logmodel.fit(df_dataset_train_X,df_dataset_train_y)\n",
    "predictions = logmodel.predict(df_dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 2 : SVM/SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Building a Support Vector Machine on train data\n",
    "svc_model = SVC(C= 0.1, kernel='linear', gamma= 1)\n",
    "svc_model.fit(df_dataset_train_X,df_dataset_train_y)\n",
    "predictions = svc_model.predict(df_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_train_X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 3 : RAMDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model.fit(df_dataset_train_X,df_dataset_train_y)\n",
    "predictions = rf_model.predict(df_dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USe PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(df_dataset_train_X)\n",
    "X_pca = pca.transform(df_dataset_train_X)\n",
    "X_pca.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='k', lw=2)\n",
    "\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "\n",
    "plt.xlim(0, 18)\n",
    "plt.yticks(np.arange(0.9, 1.0, 0.05))\n",
    "\n",
    "plt.axvline(2, c='b')\n",
    "\n",
    "plt.axhline(0.95, c='r')\n",
    "plt.axhline(0.96, c='r')\n",
    "plt.axhline(0.97, c='r')\n",
    "plt.axhline(0.98, c='r')\n",
    "plt.axhline(0.99, c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df_dataset_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL 4 : RAMDOM FOREST with PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, bootstrap = True, max_features = 'sqrt')\n",
    "rf_model.fit(pca.transform(df_dataset_train_X), df_dataset_train_y)\n",
    "predictions = rf_model.predict(pca.transform(df_dataset_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 5 :USE >LINEAR REGRESSION (MAY BE WASTE)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(df_dataset_train_X, df_dataset_train_y)\n",
    "predictions = regression_model.predict(df_dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = predicted_ratings.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_ratings = pd.concat([df_linkage_test,predicted_ratings],axis=1)\n",
    "df_final_ratings.drop(columns=['tag'],inplace=True)\n",
    "df_final_ratings.to_csv(\"Submission_Narayanan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
